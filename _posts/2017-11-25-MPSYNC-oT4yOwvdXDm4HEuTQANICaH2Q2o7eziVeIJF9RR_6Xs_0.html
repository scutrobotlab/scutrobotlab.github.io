---
categories: [新闻]
date: 2017-11-25 21:07:27 +0800
desc: 错过了感恩节的火鸡，我们还有美味的蛋糕。
layout: mp-sync
slug: 干货｜切糕大师眼中的人工神经网络
tags: [微信公众号文章]
title: 干货｜切糕大师眼中的人工神经网络
...

<section label="Powered by 135editor.com" style="font-family: 微软雅黑;"><section data-role="outer" label="Powered by 135editor.com"><section data-role="outer" label="Powered by 135editor.com"><section data-role="outer" label="Powered by 135editor.com"><section data-role="outer" label="Powered by 135editor.com"><section data-role="outer" label="Powered by 135editor.com"><section data-role="paragraph" class="_135editor" style="border-width: 0px;border-style: none;border-color: initial;padding: 0px;box-sizing: border-box;" data-color="rgb(33, 33, 34)" data-custom="rgb(33, 33, 34)"><p style="font-size: 16px;"><img data-src="/static/assets/img/mp-sync/uia5dweZ372KptTfYv2qYZkLNXB4vfh7IwLvuk3v1B0aHUDECc3q9EzoDfd6G9Xx6TazfjQr23rlpU8JGXicjMAQ.gif" data-type="gif" class="" data-ratio="0.18683001531393567" data-w="653" style="font-size: 14px;line-height: inherit;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;line-height: inherit;font-size: 14px;"><br></span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;line-height: inherit;font-size: 14px;">10月底的时候，</span><span style="font-size: 14px;">DeepMind公布的最强版AlphaGo Zero（阿尔法元）能零基础“自学成才”，在通过几天的训练后，就以100比0的战绩完爆了曾经以3比0打败过世界围棋四联冠柯洁的 “阿尔法狗”。今天小编就带你们了解下Alpha Zero的核心依托——</span><strong style="font-size: 14px;max-width: 100%;">人工神经网络</strong><span style="font-size: 14px;">。</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;"><img class="lazy" data-src="http://mmbiz.qpic.cn/mmbiz_png/uia5dweZ372KptTfYv2qYZkLNXB4vfh7I9ib29GtFMXrAx7KMI0tkrMuZ1RYsPYXBILhtAIo6VkRjRZb8iaVEwpSQ/0" style="display: inline;" data-ratio="0.5" data-w="630"></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;font-size: 14px;line-height: inherit;">人工神经网络，简单的来说是<span style="max-width: 100%;color: #333333;font-size: 14.6667px;line-height: 24.9333px;">模仿人脑神经元做决策的一种算法。它</span>从信息处理角度对<strong style="max-width: 100%;">人脑神经元网络</strong>进行抽象， 建立某种简单模型，按不同的连接方式组成不同的网络。今天小编就举个人工神经网络如何一步步切出我们心仪的<strong style="max-width: 100%;">蛋糕</strong>为例来满足下你们小小的好奇心~</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;"><span style="max-width: 100%;line-height: inherit;font-size: 14px;"><img class="lazy" data-src="http://mmbiz.qpic.cn/mmbiz_jpg/uia5dweZ372KptTfYv2qYZkLNXB4vfh7IGmFgyAL3g4PZyuvsUw2bFcP7z1L6icVmxVdMCPiaUGulqDHuYN7gicLIQ/0" style="display: inline;" data-ratio="0.5594594594594594" data-w="740"></span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;"><strong style="max-width: 100%;line-height: 25.6px;white-space: normal;"><span style="max-width: 100%;color: #FFFFFF;line-height: 22.4px;background-color: #212122;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;text-align: center;widows: 1;white-space: normal;"><span style="max-width: 100%;color: #FFFFFF;line-height: 22.4px;background-color: #212122;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;text-align: center;widows: 1;white-space: normal;"><span style="max-width: 100%;color: #FFFFFF;line-height: 22.4px;background-color: #007AAA;">01  感知器——一刀流</span></strong></span></strong></span></strong></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;font-size: 14px;">我们先来看看下面这款芝士巧克力双拼蛋糕，左边是芝士，右边是巧克力。聪明的你们简单地观察，就能分辨”芝士“和“巧克力”。那么人工神经网络又是怎样将它们进行区分的呢？</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;"><img class="lazy" data-src="http://mmbiz.qpic.cn/mmbiz_jpg/uia5dweZ372KptTfYv2qYZkLNXB4vfh7IbiaiagnyEICHTs4ukYTibt75KY5dULZco4t0LBpQFGg2ex84jAObyTvdw/0" style="display: inline;" data-ratio="1" data-w="500"></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;font-size: 14px;">最快速的分辨就是在平面中间切下一刀，左边是芝士，右边是巧克力。在人工神经网络中谁来切下这一刀，判断在哪个方位来切？答案就是<strong style="max-width: 100%;">感知器</strong>（Perceptron)。感知机就是一个将两类物体分开的超平面。超平面这里可以理解为切蛋糕的刀。话不多说，切糕要紧～😋</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;"><img class="lazy" data-src="http://mmbiz.qpic.cn/mmbiz_jpg/uia5dweZ372KptTfYv2qYZkLNXB4vfh7IJcej6fMaybjEj3icrcyia5NlXXuMNrhd3V0w3rS85VYP8ibPMKTFqT8Bg/0" style="display: inline;" data-ratio="1" data-w="500"></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;font-size: 14px;">①假设人工神经网络是通过<strong>颜色</strong>和<strong>硬度</strong>来区分这两种口味蛋糕，分成三个参数值，<strong>颜色值X1</strong>，<strong>硬度值X2</strong>，和“1”。</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;font-size: 14px;">②再假设根据颜色值大小的不同，我们能够更加容易的分辨这两种蛋糕，那么就主要以X1来分辨；X2作用较小，“1”作为调节。因此，X1、X2和“1”所占的比重各不相同，我们称这个比重为<strong style="max-width: 100%;">“权重”</strong>。</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;font-size: 14px;">③假设X1,X2和1所对应的权重分别是a、b和c，再利用一个简单的直线方程（实际方程可能更复杂）f(X)=a*X1+b*X2+c*1进行计算得到一个数值。直线可以理解为刀切下去的方向。</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;font-size: 14px;">④数值大于0表明（X1，X2）在直线（刀）的一侧，小于0则在直线（刀）的另一侧。这样我们就可以吃到美味的芝士蛋糕啦～</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;font-size: 14px;">以上是二维的情况，如果在n维度的情况下，感知机该如何下刀。<span style="max-width: 100%;color: #262626;">一条直线把平面一分为二，一个平面把三维空间一分为二，一个n-1维超平面把n维空间一分为二。</span></span><span style="max-width: 100%;font-size: 14px;line-height: inherit;">所以类似二维直线方程，把方程</span><span style="max-width: 100%;font-size: 14px;line-height: inherit;color: #262626;">推广到n维空间里。直线的高维形式称为<strong style="max-width: 100%;">超平面</strong>，它的方程是：</span><span style="max-width: 100%;color: #262626;font-size: 14px;line-height: inherit;">h=a1x1+a2x2+...+anxn+a0=0</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;"><img class="lazy" data-src="http://mmbiz.qpic.cn/mmbiz_png/uia5dweZ372KptTfYv2qYZkLNXB4vfh7IGS8gRUnRvibZ9slibib6EticufamdTkKoBMibIL69vXD9S5OskBnSia9Mr0g/0" style="display: inline;" data-ratio="0.6198347107438017" data-w="726"></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;font-size: 14px;"><span style="max-width: 100%;color: #262626;">举个例子，上面的图是</span>一个六维的点，X2~7是6个参数值，X1则是偏差值。在机器学习中，这样的点称为“<strong style="max-width: 100%;">数据</strong>”，而各个维度的坐标大小称之为“<strong style="max-width: 100%;">特征</strong>”。我们将数据特征输进感知机，<span style="max-width: 100%;color: #262626;">感知器就是当h大于0时输出1，h小于0时输出0。这样</span>感知机就能告诉我这个点是属于“芝士”还是“巧克力”了。</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;font-size: 14px;">专业的来说，感知机是对信息进行编码、压缩、集成、融合的计算机智能接口系统。（吃货看来就是一把刀´◔‸◔`）</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;"><strong style="max-width: 100%;line-height: 25.6px;white-space: normal;"><span style="max-width: 100%;color: #FFFFFF;line-height: 22.4px;background-color: #212122;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;text-align: center;widows: 1;white-space: normal;"><span style="max-width: 100%;color: #FFFFFF;line-height: 22.4px;background-color: #212122;"></span></strong><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;text-align: center;widows: 1;white-space: normal;"><span style="max-width: 100%;color: #FFFFFF;line-height: 22.4px;background-color: #212122;"></span></strong><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;text-align: center;widows: 1;white-space: normal;"><span style="max-width: 100%;color: #FFFFFF;line-height: 22.4px;background-color: #212122;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;text-align: center;widows: 1;white-space: normal;"><span style="max-width: 100%;color: #FFFFFF;line-height: 22.4px;background-color: #007AAA;">02  神经网络——多刀流</span></strong></span></strong></span></strong></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;font-size: 14px;">感知机的局限在于，因为它是一条直线（一个超平面），也就是说，只能分辨出一条直线切出两边各一种蛋糕。那么遇到<strong style="max-width: 100%;">非线性可分</strong>的蛋糕集（数据集），感知器又该怎么切？比如四拼蛋糕。</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;"><span style="max-width: 100%;font-size: 14px;"><img class="lazy" data-src="http://mmbiz.qpic.cn/mmbiz_jpg/uia5dweZ372KptTfYv2qYZkLNXB4vfh7I9pZDY27w3tyL8lP3rD8iccppac7R5BHUjeZ2K0DWkNAqbUs69yXsWQA/0" style="display: inline;" data-ratio="0.584375" data-w="640"></span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;font-size: 14px;">在四拼蛋糕中，这次我们想要那个<strong style="max-width: 100%;">榴莲口味</strong>的蛋糕。一个感知机只能切一刀显然不够，这时感知器的小伙伴就可以帮忙再切一刀。</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;"><span style="max-width: 100%;font-size: 14px;"><img class="lazy" data-src="/static/assets/img/mp-sync/uia5dweZ372KptTfYv2qYZkLNXB4vfh7IhibepzmE5DyzZn4AuHtAXyqr6uT6KJvibFjXvRdw1xBAbKz7cs6yeblg.gif" style="display: inline;" data-type="gif" data-ratio="0.6674528301886793" data-w="848"></span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;font-size: 14px;">推崇民主的感知机们，都喜欢用投票的方式来决定选择的这块蛋糕到底是什么类型。但是如果这群感知机的数量足够多而且每个感知机的想法都不太一样。那么要将它们结合到一起，切出满意的结果，就可以根据感知机的分辨能力各不相同，来<strong style="max-width: 100%;">分配权重</strong>。分辨能力越强的感知机判断结果所占的权重也越大。</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;"><img data-src="http://mmbiz.qpic.cn/mmbiz_png/uia5dweZ372KptTfYv2qYZkLNXB4vfh7IaYXW3jtmvE0ZyR276z3Kf79xCZDwRSckmiaF29yYQFxgrpK3ueTpGIw/0" class="" data-ratio="0.6362994350282486" data-w="1416"></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;font-size: 14px;">看上面图，V1~V5就是五位感知机手里的票数，也就是它们的权重，将他们的结果按照权重加起来，再和0比较（扔进可以微分的<strong style="max-width: 100%;">tanh</strong>函数或<strong style="max-width: 100%;">sigmoid</strong>函数）。这样综合各个感知器的投票，就能够找到最适合的切糕方式了。</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;"><span style="max-width: 100%;font-size: 14px;"><img class="lazy" data-src="http://mmbiz.qpic.cn/mmbiz_png/uia5dweZ372KptTfYv2qYZkLNXB4vfh7IwUZkZmfWfmJ49d4VF3YV2KIDSg0WWbyibN0s2wEhm7PTicIUict3T3M6Q/0" style="display: inline;" data-ratio="0.7373949579831933" data-w="476"></span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;font-size: 14px;line-height: inherit;">在机器学习中，这种通过构建并结合多个学习器来完成学习的方法叫“<strong style="max-width: 100%;">集合学习</strong>（Aggregation）”。这种多个感知机集合在一起做投票的模型就是神经网络。在神经网络中，我们可以把感知器看作是神经元。数据输入的一列神经元称为<strong style="max-width: 100%;">输入层</strong>（Input Layer），中间的神经元属于是<strong style="max-width: 100%;">隐藏层</strong>（Hidden Layer），而最后输出结果的则是<strong style="max-width: 100%;">输出层</strong>（Output Layer）。</span><br style="max-width: 100%;"></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;"><img data-src="http://mmbiz.qpic.cn/mmbiz_png/uia5dweZ372KptTfYv2qYZkLNXB4vfh7IsqrdjQ617gGxQ8FDQLpQMia2k373Qj5Zjh0cLwbv1GdrAEI4ygMYfSg/0" class="" data-ratio="0.6671289875173371" data-w="1442"></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;font-size: 14px;">神经网络的每一层的神经元数量都可以改变的，隐藏层中神经元数量增加的会让神经网络的学习能力变得更强大。例如，具有分辨气味能力的神经网络，可以更快切出我们想要的蛋糕。</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;font-size: 14px;">如果输出层不只有一个神经元，那么这个神经网络就可以做<strong style="max-width: 100%;">多元分类</strong>。例如下图输出层有两个神经元的神经网络，就可以输出[1 1]，[1 -1]，[-1 1]，[-1 -1]四种可能（不用-1而是用0来编码），那么就可以做四元分类了。让我们在切糕的同时还可以切点别的。</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;"><span style="max-width: 100%;font-size: 14px;"><img class="lazy" data-src="http://mmbiz.qpic.cn/mmbiz_png/uia5dweZ372KptTfYv2qYZkLNXB4vfh7IXATEabogXwrZmaic7KoUzYt8mqzQGogJK5AaHTeSbyOibVY6d8ZyUrKQ/0" style="display: inline;" data-ratio="1.131764705882353" data-w="425"></span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;"><strong style="max-width: 100%;line-height: 25.6px;white-space: normal;"><span style="max-width: 100%;color: #FFFFFF;line-height: 22.4px;background-color: #212122;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;text-align: center;widows: 1;white-space: normal;"><span style="max-width: 100%;color: #FFFFFF;line-height: 22.4px;background-color: #007AAA;">训练神经网络——练刀流</span></strong></span></strong></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;font-size: 14px;line-height: inherit;">蛋糕种类再多有了神经网络，麻麻再也不担心你们吃不到心仪的蛋糕了。嗯～可是要是你们想尽快吃到蛋糕呢？这就需要训练神经网络，让他们能更快速的分辨蛋糕。</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="font-size: 14px;">这里介绍一种训练神经网络方法——</span><strong style="font-size: 14px;max-width: 100%;">梯度下降法</strong><span style="font-size: 14px;">。通过分配正确的权重给机智的感知机，让它们带领神经网络快速走向胜利。</span><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;font-size: 14px;">以二维数据作为例子，这两维的权重是Θ0和Θ1，,我们将神经网络犯错的数量表达成一个函数J（<strong style="max-width: 100%;">损失函数</strong>Cost Function）。</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="font-size: 14px;">J越大，证明犯错越多，就像红色的山峰；J越小，证明犯错越少，例如蓝色的山脚所在点。在梯度下降中，不断地改变Θ0，Θ1的值，使得J(Θ0，Θ1)变小，直到找到J的最小值或许是局部最小值。</span><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;"><span style="max-width: 100%;font-size: 14px;"><img class="lazy" data-src="http://mmbiz.qpic.cn/mmbiz_png/uia5dweZ372KptTfYv2qYZkLNXB4vfh7I5RLrTsS38LRD2Nv1IXXC3zYTRlGGCgENvcCcRVNsowJicTEYNAFg13g/0" style="display: inline;" data-ratio="0.4841040462427746" data-w="692"></span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;font-size: 14px;">看不懂上面的没关系，我们情景设想下——我们现在需要下山才能吃蛋糕，而且希望尽早吃到蛋糕。</span><span style="max-width: 100%;font-size: 14px;line-height: inherit;">借助GPS下山,Θ0和Θ1对应的是经度和维度，而J则是高度，在安全的前提下，走越陡峭的路就能越快下山。</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;font-size: 14px;line-height: inherit;"><img class="lazy" data-src="http://mmbiz.qpic.cn/mmbiz_jpg/uia5dweZ372KptTfYv2qYZkLNXB4vfh7IiaxcgBszDFGdTEzDlPeTFCuUXGIaH9PkmQCUo5icFcQLkuuwBLMQWIAg/0" style="display: inline;" data-ratio="0.705" data-w="600"></span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;font-size: 14px;line-height: inherit;">下面我们介绍如何找这个最陡的方向：</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;font-size: 14px;line-height: inherit;">①我们对J求每一个权重Θj的偏导数，即梯度</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;"><span style="max-width: 100%;font-size: 14px;line-height: inherit;"><img class="lazy" height="131" data-src="http://mmbiz.qpic.cn/mmbiz_png/uia5dweZ372KptTfYv2qYZkLNXB4vfh7IqYqV42EYrQtuSewxWvzLqt80iaHiaXjH2Db3scJic5JJbvicWLf4edNdDQ/0" style="height: 131px;width: 287px;display: inline;" width="287" data-ratio="0.45714285714285713" data-w="315"></span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;font-size: 14px;line-height: inherit;">②然后我们对在这个最陡的方向走α步，即</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;"><span style="max-width: 100%;font-size: 14px;line-height: inherit;"><img class="lazy" data-src="http://mmbiz.qpic.cn/mmbiz_png/uia5dweZ372KptTfYv2qYZkLNXB4vfh7I27wZnNbPQvZJFBXkxSdEHBJibZlgS7p7EKN8rGbmOrJGOp99ib4adIBQ/0" style="display: inline;" data-ratio="0.1951219512195122" data-w="615"></span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;font-size: 14px;line-height: inherit;">③走完之后，停下来，找到新的最陡的方向，再走α步，一直到我们走到了山脚。</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;font-size: 14px;line-height: inherit;"><img class="lazy" data-src="http://mmbiz.qpic.cn/mmbiz_png/uia5dweZ372KptTfYv2qYZkLNXB4vfh7IkJ7o5ehP6bf09bvBYoJoKxextY8AzpSuXXuSMxkfrwzLyKIjI1kc2Q/0" style="display: inline;" data-ratio="0.1934566145092461" data-w="703"></span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;font-size: 14px;line-height: inherit;">这样我们就找到了最快下山的道路啦，即最优化的权重。就可以吃上美味的蛋糕啦~</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;font-size: 14px;line-height: inherit;"><img data-src="http://mmbiz.qpic.cn/mmbiz_jpg/uia5dweZ372KptTfYv2qYZkLNXB4vfh7IkicJ90CT2x8LxvlxO2qeWPmLuD8wxymHSHDDVs7gGz4J5b601TSTGicg/0" class="" data-ratio="0.7166666666666667" data-w="1200"></span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;font-size: 14px;line-height: inherit;">不过梯度下降法有时会陷入<strong style="max-width: 100%;">局部最优化</strong>的<strong style="max-width: 100%;">危险</strong><strong style="max-width: 100%;"><span style="max-width: 100%;line-height: inherit;color: #212122;">（就是我们下到局部最低点，但这里并没有蛋糕，即这里并不是全局最低点）</span></strong>，但是大多数我们需要解决的问题大多都是局部最优化=全局最优化的，所以也并不需要太担心。</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;"><strong style="max-width: 100%;line-height: 25.6px;white-space: normal;"><span style="max-width: 100%;color: #FFFFFF;line-height: 22.4px;background-color: #212122;"></span></strong><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;text-align: center;widows: 1;white-space: normal;"><span style="max-width: 100%;color: #FFFFFF;line-height: 22.4px;background-color: #007AAA;">深度神经网络——智刀流</span></strong></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;font-size: 14px;"><span class="author-1904075" style="max-width: 100%;border-bottom: 0px solid #212122;">前面谈到神经网络结构中，每一层的神经元数量是可以变化的。其实隐藏层的数量也是可以变化的，多隐藏层的神经网络其实就是</span><span style="max-width: 100%;color: #000000;"><strong style="max-width: 100%;"><span class="author-1904075 font-color-4" style="max-width: 100%;border-bottom: 0px solid #212122;">深度神经网络</span></strong></span><span class="author-1904075" style="max-width: 100%;border-bottom: 0px solid #212122;">。深度神经网络比浅层的神经网络</span></span><span style="max-width: 100%;font-size: 14px;max-width: 100%;border-bottom: 0px solid #212122;">具有更强的学习能力，能提供更复杂的模型，相比于浅层神经网络，深度神经网络能学到更多的“意义”。</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="font-size: 14px;max-width: 100%;border-bottom: 0px solid #212122;"><img class="lazy" data-src="http://mmbiz.qpic.cn/mmbiz_jpg/uia5dweZ372KptTfYv2qYZkLNXB4vfh7IlwJ41cKpKicAp7tuQHvf5JiaiayFPmrSymeR4WRWUtjsm3suD8dK2nWSQ/0" style="display: inline;" data-ratio="0.645" data-w="600"></span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="font-size: 14px;max-width: 100%;border-bottom: 0px solid #212122;">不知道什么意思，没关系。</span><span style="max-width: 100%;border-bottom: 0px solid #212122;font-size: 14px;">在你们的脑海里，经过一层又一层的筛选，最终找到自己最爱的那一块蛋糕——一块黑森林蛋糕，顶层淋上奶油再加点巧克力片，然后有一颗颜色鲜红的樱桃点缀，也许盘子里再加点绿色的装饰品，</span><span style="font-size: 14px;">现在举个多隐藏层的神经网络如何识别的例子：</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;border-bottom: 0px solid #212122;font-size: 14px;">第一层：神经元主要负责识别颜色和简单纹理。</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;"><span style="max-width: 100%;border-bottom: 0px solid #212122;font-size: 14px;"><img class="lazy" data-src="http://mmbiz.qpic.cn/mmbiz_png/uia5dweZ372KptTfYv2qYZkLNXB4vfh7Iz9iaXkwLt0lj2NlD0OicKTWV1VuKUN9ruPS6Rqy7ia413r7rYYn4GicSLA/0" style="display: inline;" data-ratio="0.5372670807453416" data-w="966"></span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;border-bottom: 0px solid #212122;font-size: 14px;">第二层：一些神经元可以识别更加细化的纹理，比如布纹、刻度、叶纹。<br style="max-width: 100%;"></span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;border-bottom: 0px solid #212122;font-size: 14px;"><img class="lazy" data-src="http://mmbiz.qpic.cn/mmbiz_png/uia5dweZ372KptTfYv2qYZkLNXB4vfh7ICVdGdIO8I2JLrY1qU7TzLDuy7pXXaozZEXJ4RibST5tGOtk3NmFXDMA/0" style="display: inline;" data-ratio="0.4996214988644966" data-w="1321"></span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;border-bottom: 0px solid #212122;font-size: 14px;">第三层：一些神经元可以感受黑夜里的黄色烛光、鸡蛋黄、高光。</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;border-bottom: 0px solid #212122;font-size: 14px;"><img class="lazy" data-src="http://mmbiz.qpic.cn/mmbiz_png/uia5dweZ372KptTfYv2qYZkLNXB4vfh7Ik7wTN9VdNzFuZ5L51FONBEHQWJfnE8wdhB298iaCtT0qMy1I1RekXHQ/0" style="display: inline;" data-ratio="0.5056947608200456" data-w="1317"></span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;border-bottom: 0px solid #212122;font-size: 14px;">第四层：一些神经元负责识别萌狗的脸、七星瓢虫和一堆圆形物体的存在。</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;border-bottom: 0px solid #212122;font-size: 14px;"><img class="lazy" data-src="http://mmbiz.qpic.cn/mmbiz_png/uia5dweZ372KptTfYv2qYZkLNXB4vfh7IXFnibD2BfsdLjlh4LI1YkmwjibMbnZPAUaSiaan5l45NeLU2yeibFcYU7g/0" style="display: inline;" data-ratio="0.460546282245827" data-w="1318"></span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;border-bottom: 0px solid #212122;font-size: 14px;">第五层：一些神经元可以识别出花、圆形屋顶、键盘、鸟、黑眼圈动物。</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;border-bottom: 0px solid #212122;font-size: 14px;"><img class="lazy" data-src="http://mmbiz.qpic.cn/mmbiz_png/uia5dweZ372KptTfYv2qYZkLNXB4vfh7IBGZ1WsUNuRicGZO2bJJkO4CJ6xfLYcm63bglZqwnbrEIJI6ln380UwA/0" style="display: inline;" data-ratio="0.5644916540212443" data-w="1318"></span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;border-bottom: 0px solid #212122;font-size: 14px;">我们可以发现，越深层的神经网络，能够学习到更抽象的“概念”，比如萌狗、花等，浅层神经网络只懂得简单的线条。这说明深度神经网络才能够挑选出符合我们脑海中最喜爱的蛋糕啦。</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><img data-src="http://mmbiz.qpic.cn/mmbiz_jpg/uia5dweZ372KptTfYv2qYZkLNXB4vfh7Iqr5bU8EibUMeOb7J8k6iaDp1FRW4noyoVPpPVaa6OxsPJ7UUpsSxkwjA/0" class="" data-ratio="0.5281995661605207" data-w="922"></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;border-bottom: 0px solid #212122;font-size: 14px;">但是深层的神经网络需要训练的时间更长，需要的数据量也更大，而且往往会陷入过拟合的危险中。所以如何训练出一个优秀的神经网络成为了众多工程师亟待解决的问题。</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;border-bottom: 0px solid #212122;font-size: 14px;">这里又谈到了一个概念——</span><span style="color: #000000;"><strong><span style="border-bottom: 0px solid #212122;max-width: 100%;font-size: 14px;">过拟合</span></strong></span><span style="max-width: 100%;border-bottom: 0px solid #212122;font-size: 14px;">，过拟合是吃糕专家们一直为之头痛的问题。<span style="max-width: 100%;font-size: 14px;color: #000000;">过拟合是指为了得到一致假设而使假设变得过度严格。</span>例如，训练了很久切奶油蛋糕，突然要切巧克力蛋糕反而不会了。</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;border-bottom: 0px solid #212122;font-size: 14px;">对于解决过拟合的办法，我们往往会做正则化（Regularization）。举个例子，我们会在神经网络的损失函数J中加入regularizer，如Θ^2，去惩罚过于复杂的模型，避免过拟合。<br style="max-width: 100%;"></span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;border-bottom: 0px solid #212122;font-size: 14px;"><img data-src="http://mmbiz.qpic.cn/mmbiz_png/uia5dweZ372KptTfYv2qYZkLNXB4vfh7I5iaKViblRscobl0S0iaIuicdbjhXyONkiaKCAiaL8iarnicd5MWyCx8CbWBbnw/0" class="" data-ratio="0.31991411701556627" data-w="1863"></span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="color: rgb(0, 122, 170);"></span><br></p><p style="font-size: 16px;text-align: center;widows: 1;max-width: 100%;min-height: 1em;"><span style="color:#ffffff;font-size: 14px;background-color: #007AAA;"><strong>更多的切糕大师</strong></span></p><p style="font-size: 16px;widows: 1;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;widows: 1;max-width: 100%;min-height: 1em;"><span style="font-size: 14px;">今天所讲神经网络的只是最简单的BP神经网络，除此之外还有卷积神经网络、ART网络、SOM网络、Elman网络、RBF网络等，想知道他们是怎么切成不同的蛋糕，大家就要继续学习挖掘了，说不定下一个切糕大师就是你。</span></p><p style="max-width: 100%;min-height: 1em;"><span style="font-size: 12px;"><br></span></p><p style="max-width: 100%;min-height: 1em;"><span style="font-size: 12px;">参考文献：</span><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;border-bottom: 0px solid #212122;font-size: 10px;">[1] 机器学习 周志华 著</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;border-bottom: 0px solid #212122;font-size: 10px;">[2] 统计学习方法 李航 著</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="font-size: 10px;">[3] Stanford Machine Learning in Coursera 主讲 Andrew Ng</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;border-bottom: 0px solid #212122;font-size: 10px;">[4] Machine Learning Foundation 主讲 国立台湾大学 林轩田</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;border-bottom: 0px solid #212122;font-size: 10px;">[4] Machine Learning Technique 主讲 国立台湾大学 林轩田</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;border-bottom: 0px solid #212122;font-size: 10px;"><br></span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;border-bottom: 0px solid #212122;font-size: 10px;"><br></span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><span style="max-width: 100%;border-bottom: 0px solid rgb(33, 33, 34);font-family: 微软雅黑;font-size: 14px;color: rgb(63, 63, 63);">看完这一期人工神经网络，你有什么想说的，一起在留言区凑热闹吧！点赞数最多的盆友可以获得<span style="max-width: 100%;font-family: 微软雅黑;font-size: 14px;color: rgb(0, 122, 170);">《机甲大师》动漫Q版人物钥匙扣</span>一个！如果你想加入萌虎写手团，也欢迎在微信后台联系我们！</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;"><span style="color: rgb(0, 122, 170);">◆<span style="font-family: 微软雅黑;font-size: 16px;">◆◆</span></span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;"><span style="color: rgb(0, 122, 170);"><span style="font-family: 微软雅黑;font-size: 16px;"><br></span></span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;"><span style="font-size: 14px;color: rgb(63, 63, 63);">文/片片</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;"><span style="font-size: 14px;color: rgb(63, 63, 63);">编辑/Tabb、Bingo</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;"><span style="font-size: 14px;color: rgb(63, 63, 63);">审核/王木木</span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;text-align: right;"><span style="font-size: 14px;color: rgb(63, 63, 63);"><br></span></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;text-align: right;"><br></p><p style="font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;"><img class="lazy" data-src="http://mmbiz.qpic.cn/mmbiz_jpg/uia5dweZ372KptTfYv2qYZkLNXB4vfh7IdfKhLbXXicicrg22zOayqLzcweNT9THKmDZVYn4nvuGfu6xiaFhnK0PVQ/0" style="display: inline;width: 100%;height: auto;" data-ratio="1" data-w="640" data-backw="556" data-backh="556"></p><p style="font-size: 16px;"><br></p><p style="font-size: 16px;"><br></p></section></section></section></section></section></section></section>